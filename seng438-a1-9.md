>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: 9          |
|-------------------|
| Maheen Raza       |   
| Mehrnaz Zafari    |   
| Chloe Villaranda  |   
| Maham Jamal       |   



**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was
divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons
learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction

An introduction of your lab work, and what you knew about exploratory and manual functional testing before this lab:

By participating in lab 1 for SENG 438 - Introduction to Testing and Defect Tracking - our group dove head first into what it's like to test software for bugs, especially without any special guidance. From other classes, most of us had the experience of writing coded unit tests themselves to test specific functionalities within code. By conducting these tests, we've learned different methods to track bugs and observe if they have been resolved.

Prior to this lab, the majority of us had no idea what 'exploratory' testing was. Before approaching the software, we were confused, wondering if we were even doing it correctly. Realizing that the main idea of 'exploratory' testing is to create and execute tests as we go, we got more comfortable doing so.

Even though none of us had explicit experience doing manual functional testing prior to this lab, it was a lot easier to comprehend and complete in comparsion to the exploratory testing phase, as we knew it would involve test cases that weree already configured and ready to be executed. Going through explicit test cases and tracking if they pass or fail was a lot more easier to do, and we were a lot more confident going into it.

# High-level description of the exploratory testing plan

For our exploratory testing, the test charter we agreed on was to 'determine if the program meets all specified requirements.' We aimed to target all functions by using team exploratory testing and employed the "tour bus" principle, a term coined by Cem Kaner. This principle outlines that a general plan is drawn up and the tester tries out more things when undesired behavior is seen. We planned to test all functions briefly and delve deeper when any bugs were noticed by trying to recreate the bug with a different order of steps. We decided to test the most common paths as well as exceptional paths. Below you can see our test coverage outline:

Customer interaction 

- Wrong card number
- Pin validation 
- Bank inquiries 
- 3 invalid pins 

Transaction services

- Cash withdrawals (from chequing and savings) 
- Cash deposits 
- Cash transfers

Error Handling

- Canceling a transaction mid-way
- Withdrawing an amount larger than available 
- Withdrawing from an empty account

The outline specifies 3 broad categories we wanted to cover and specific use cases within each.


# Comparison of exploratory and manual functional testing

Exploratory testing and functional testing are two different approaches taken to test if an application meets requirements. Each varies from one another in terms of benefits, tradeoffs, effectiveness, and efficiency. 

Exploratory testing proved to be far more efficient than manual functional testing, which was far more time-consuming. As we had a high-level plan drawn up, we were able to complete the testing much faster than working through the forty test cases in the test suite. Exploratory testing was far more adaptable than manual functional testing. We were able to explore the application at our own will and repeat certain use cases, for example, completing actions in different orders to verify if the bug was dependent on something else happening first. This method is a lot more logical, as we test through the eyes of a user, and follow through steps they might do. Manual functional testing was beneficial in terms of being incredibly sufficient and comprehensive. During and after the exploratory testing phase, we weren't sure if we had uncovered all the bugs possible. The manual functional testing had a far more structured approach with a start and end. Within the test suite, multiple scenarios were covered for each function as well. Practically, we rediscovered all bugs found in exploratory testing using the test suite and found an additional 3 bugs during the manual functional testing phase. In terms of documentation, manual functional testing was superior. The bugs were far easier to document as everything required for the bug report was already defined in the test suite. With exploratory testing, the recorder had to take great care in keeping track of each action the tester was taking, as well as recording said bug. 

-   Note that you need to submit a report generated by your defect tracking
    system, containing all defects recorded in the system.

# Notes and discussion of the peer reviews of defect reports

After each pair completed the exploratory testing phase, a handful of bugs were found in the software through test cases that also incidentally matched the test cases in the given SUT in the manual scripted testing phase. This demonstrates the excellent ability that our group performed when running exploratory tests, as we managed to find the important bugs that a user of the ATM system might stumble across. After reviewing the defect reports in Azure, all the recorded bugs made sense, and were present in the subsequent versions if marked active. Each bug met the requirements of the software described in the lab guidelines.

# How the pair testing was managed and teamwork/effort was divided 

For exploratory testing, our group broke into pairs. The tester was responsible for guiding the testing and the other partner took on the role of a recorder, they noted down each action taken by the tester at every point. When a bug was found, both the tester and recorder worked together to note the bug down using AzureDevOps.

For manual testing, the group worked together. One person used the program, one organized the order to perform tests, one recorded any bugs found in AzureDevOps and the last member double-checked all bugs to ensure no duplicates were seen.

For regression testing, we split the 40 manual tests as well as the number of bugs found in version 1.0 amongst ourselves (10 tests/member) and recorded any new defects.

Overall, we agreed the workload and effort were split evenly.

# Difficulties encountered, challenges overcome, and lessons learned

As this was our first time completing "exploratory testing", we would struggle to define our high-level test plan initially. After realizing that the whole point of exploratory testing is to essentially explore the application, it became a lot easier, as we would test certain functionalities that users might use on a day-to-day basis. One lesson we've learned is how important it can be to do exploratory testing, instead of having explicit test cases listed out. It helps to test common features that testers can think of, as well as build more test cases from previous ones completed.

# Comments/feedback on the lab and lab document itself

Overall, the lab was a great way to get hands-on experience when it comes to testing, as it really soldified the ideas and differences between exploratory and manual scripted testing. The lab document was comprehensive in providing relevant information in order to complete the lab. It would have been nice that since the concepts were new to us, to have additional resources to be able to look to during the times that we might have been stuck.